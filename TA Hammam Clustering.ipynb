{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Git Repo Hammam Tugas Akhir\r\n",
    "import csv\r\n",
    "import regex\r\n",
    "import datetime as dt\r\n",
    "from datetime import timedelta\r\n",
    "import locale\r\n",
    "locale.setlocale(locale.LC_TIME, 'id-ID.UTF-8')\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from scipy import stats\r\n",
    "from scipy.spatial.distance import cdist\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "sns.set_style(\"whitegrid\")\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")\r\n",
    "#from feature_engine.outlier_removers import Winsorizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv(\"Coret-Coret Marketing_Transaction Details (TA Hammam)_2006-2105.csv\")\r\n",
    "# df = pd.read_csv(\"Coret-Coret Marketing_Transaction Details (TA Hammam)_2003-2105.csv\")\r\n",
    "# df = pd.read_csv(\"Coret-Coret Marketing_Transaction Details (TA Hammam)_1904-2104.csv\")\r\n",
    "display(df.info())\r\n",
    "df.to_csv(\"Hasil/Data_TA.csv\")\r\n",
    "df.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Dataset dimension : \" + str(df.shape))\r\n",
    "print('Jumlah Customer : ' + str(len(pd.unique(df['telp']))))\r\n",
    "print('Jumlah Transaksi : ' + str(len(pd.unique(df['no_order']))))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Clean unused atribute\r\n",
    "df.drop(['transaction_type', 'ID CL', 'nama_komunitas', 'username', 'useremail', 'prod_id', 'harga', 'qty'],axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clean Telp"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Drop Null\r\n",
    "df.dropna(inplace=True)\r\n",
    "\r\n",
    "#standarize telp number\r\n",
    "df['telp'] = df['telp'].str.replace('-','')\r\n",
    "df['telp'] = df['telp'].str.replace(' ','')\r\n",
    "df['telp'] = df['telp'].str.replace('+','')\r\n",
    "df['telp'] = df['telp'].str.replace('08', '628', 1)\r\n",
    "df = df[df['telp'].str.startswith('628')]\r\n",
    "\r\n",
    "#Clean admin no hp & Invalid\r\n",
    "df = df.drop(df[df.telp.eq('6281381306699')\r\n",
    "                | df.telp.eq('0')].index)\r\n",
    "df = df[~df['telp'].str.contains('1234567')]\r\n",
    "\r\n",
    "#drop number with invalid character\r\n",
    "df = df.drop(df[df.telp.str.contains(r'[^0-9a-zA-Z]')\r\n",
    "                | df.telp.str.contains(r'[a-zA-Z]')].index)\r\n",
    "                \r\n",
    "#drop abnormal telpon length\r\n",
    "df = df[df['telp'].str.len() > 10]\r\n",
    "df = df[df['telp'].str.len() < 15]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clean Name, Channel, Product"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Clean penyesuaian, test, dan keperluan internal\n",
    "testing = ['test', 'testing', 'COBAAA', 'tes123', 'TEXTING', 'penyesuaian', 'penyelamatan', 'stok', 'stock', 'tamu', 'b2b']\n",
    "df = df[~df['name'].str.contains('|'.join(testing))]\n",
    "\n",
    "#Clean Old B2B Customer\n",
    "B2B_cust = ['hotel', 'resto', 'restoran', 'cafe', 'coffee', 'Toko', 'toko', 'Patata', 'Geprek', 'Laziza', 'ayam', 'nasi', 'sego', 'Baksoe', 'Bakso', 'Rismart', 'Nu Mart', 'Warung', 'Rice box','E-Warung', 'ewarung', 'Kedai', 'geprek', 'nelongso', 'pkk', 'pkh']\n",
    "df = df[~df['name'].str.contains('|'.join(B2B_cust))] \n",
    "\n",
    "#Clean B2B Product\n",
    "B2Bproduct = ['B2B']\n",
    "df = df[~df['produk'].str.contains('|'.join(B2Bproduct))] \n",
    "\n",
    "#Clean Based on Channel\n",
    "channel = ['CL', 'End User', 'Shopee']\n",
    "df = df[df['Channel'].isin(channel)]\n",
    "\n",
    "#clean status non delivered\n",
    "df = df[df.delivery_status.eq('delivered')]\n",
    "\n",
    "#Cleaning outlier (Paket donasi sembako dan grosir)\n",
    "## need futher data based technique\n",
    "donasi = ['Donasi','donasi','Pahlawan', 'Pangan', 'garda', 'sembako', 'psbb ']\n",
    "df = df[~df['name'].str.contains('|'.join(donasi))]\n",
    "df = df[(df['subtotal'] > 0)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Dataset dimension : \" + str(df.shape))\r\n",
    "print('Jumlah Customer : ' + str(len(pd.unique(df['telp']))))\r\n",
    "print('Jumlah Transaksi : ' + str(len(pd.unique(df['no_order']))))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parse datetime format\r\n",
    "df_clean = df.copy()\r\n",
    "df_clean['delivery_date'] = df_clean['delivery_date'].apply(lambda x:dt.datetime.strptime(x,'%d %b %Y'))\r\n",
    "\r\n",
    "df_clean.to_csv(\"Hasil/Data_TA Clean.csv\")\r\n",
    "df_clean.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate LRFM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#group by invoice \r\n",
    "df_group = df_clean.groupby(['no_order', 'telp', 'delivery_date'], as_index = False).agg({'subtotal':'sum'})\r\n",
    "df_group"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Group By Telp\r\n",
    "#Perform mapping to LRFM\r\n",
    "snapshot_date = df_clean['delivery_date'].max() + timedelta(days=1)\r\n",
    "lrfm = df_group.groupby(['telp']).agg(Length=('delivery_date', lambda x: (snapshot_date - x.min()).days),\r\n",
    "                                   Recency=('delivery_date', lambda x: (snapshot_date - x.max()).days),\r\n",
    "                                   Frequency=('no_order', 'count'),\r\n",
    "                                   Monetary=('subtotal', 'sum'))\r\n",
    "lrfm.to_csv(\"Hasil/Data_TA LRFM.csv\")\r\n",
    "display(lrfm)\r\n",
    "lrfm.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Check Outlier on Frequency\r\n",
    "# display(sns.boxplot(lrfm['Frequency']))\r\n",
    "\r\n",
    "# #delete outlier\r\n",
    "# lrfm = lrfm[~(lrfm['Frequency'] > 57)]\r\n",
    "# sns.boxplot(x=lrfm['Frequency'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def check_skew(df_skew, column):\r\n",
    "    skew = stats.skew(df_skew[column])\r\n",
    "    skewtest = stats.skewtest(df_skew[column])\r\n",
    "    plt.title('Distribution of ' + column)\r\n",
    "    sns.distplot(df_skew[column], kde=False)\r\n",
    "    \r\n",
    "    print(\"{}'s: Skew: {}, : {}\".format(column, skew, skewtest))\r\n",
    "    return\r\n",
    "\r\n",
    "def norm_minmax(df):\r\n",
    "    result = df.copy()\r\n",
    "    for feature_name in df.columns:\r\n",
    "        max_value = df[feature_name].max()\r\n",
    "        min_value = df[feature_name].min()\r\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\r\n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot all 4 graphs to check skewness\r\n",
    "plt.figure(figsize=(9, 9))\r\n",
    "\r\n",
    "plt.subplot(4, 1, 1)\r\n",
    "check_skew(lrfm,'Length')\r\n",
    "\r\n",
    "plt.subplot(4, 1, 2)\r\n",
    "check_skew(lrfm,'Recency')\r\n",
    "\r\n",
    "plt.subplot(4, 1, 3)\r\n",
    "check_skew(lrfm,'Frequency')\r\n",
    "\r\n",
    "plt.subplot(4, 1, 4)\r\n",
    "check_skew(lrfm,'Monetary')\r\n",
    "\r\n",
    "plt.tight_layout()\r\n",
    "plt.savefig('Grafik/before_transform.png', format='png', dpi=1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Frequency dan monetary skewnya ndak masuk akal"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformation & Normalization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lrfm_trans = lrfm.copy()\r\n",
    "\r\n",
    "lrfm_trans['Recency'] = np.sqrt(lrfm_trans['Recency'])\r\n",
    "lrfm_trans['Frequency'] = np.log10(lrfm_trans['Frequency']+1)\r\n",
    "lrfm_trans['Monetary'] = np.log10(lrfm_trans['Monetary']+1)\r\n",
    "\r\n",
    "plt.figure(figsize=(10, 10))\r\n",
    "plt.subplot(4, 1, 1)\r\n",
    "check_skew(lrfm_trans,'Length')\r\n",
    "plt.subplot(4, 1, 2)\r\n",
    "check_skew(lrfm_trans,'Recency')\r\n",
    "plt.subplot(4, 1, 3)\r\n",
    "check_skew(lrfm_trans,'Frequency')\r\n",
    "plt.subplot(4, 1, 4)\r\n",
    "check_skew(lrfm_trans,'Monetary')\r\n",
    "\r\n",
    "plt.tight_layout()\r\n",
    "plt.savefig('Grafik/after_transform-1.png', format='png', dpi=1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lrfm_trans['Frequency'] = np.sqrt(lrfm_trans['Frequency'])\r\n",
    "lrfm_trans['Monetary'] = np.sqrt(lrfm_trans['Monetary'])\r\n",
    "\r\n",
    "plt.figure(figsize=(10, 10))\r\n",
    "plt.subplot(4, 1, 1)\r\n",
    "check_skew(lrfm_trans,'Length')\r\n",
    "plt.subplot(4, 1, 2)\r\n",
    "check_skew(lrfm_trans,'Recency')\r\n",
    "plt.subplot(4, 1, 3)\r\n",
    "check_skew(lrfm_trans,'Frequency')\r\n",
    "plt.subplot(4, 1, 4)\r\n",
    "check_skew(lrfm_trans,'Monetary')\r\n",
    "\r\n",
    "plt.tight_layout()\r\n",
    "plt.savefig('Grafik/after_transform-2.png', format='png', dpi=1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lrfm_trans['Frequency'] = np.sqrt(lrfm_trans['Frequency'])\r\n",
    "\r\n",
    "plt.figure(figsize=(10, 10))\r\n",
    "plt.subplot(4, 1, 1)\r\n",
    "check_skew(lrfm_trans,'Length')\r\n",
    "plt.subplot(4, 1, 2)\r\n",
    "check_skew(lrfm_trans,'Recency')\r\n",
    "plt.subplot(4, 1, 3)\r\n",
    "check_skew(lrfm_trans,'Frequency')\r\n",
    "plt.subplot(4, 1, 4)\r\n",
    "check_skew(lrfm_trans,'Monetary')\r\n",
    "\r\n",
    "plt.tight_layout()\r\n",
    "plt.savefig('Grafik/after_transform-3.png', format='png', dpi=1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lrfm_trans['Frequency'] = np.sqrt(lrfm_trans['Frequency'])\r\n",
    "\r\n",
    "plt.figure(figsize=(10, 10))\r\n",
    "plt.subplot(4, 1, 1)\r\n",
    "check_skew(lrfm_trans,'Length')\r\n",
    "plt.subplot(4, 1, 2)\r\n",
    "check_skew(lrfm_trans,'Recency')\r\n",
    "plt.subplot(4, 1, 3)\r\n",
    "check_skew(lrfm_trans,'Frequency')\r\n",
    "plt.subplot(4, 1, 4)\r\n",
    "check_skew(lrfm_trans,'Monetary')\r\n",
    "\r\n",
    "plt.tight_layout()\r\n",
    "plt.savefig('Grafik/after_transform-4.png', format='png', dpi=1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Min-Max Normalization\r\n",
    "norm_lrfm = norm_minmax(lrfm_trans)\r\n",
    "\r\n",
    "#Mengubah nilai Recency menggunakan 1-R karena merupakan kebalikan dari variabel lain\r\n",
    "#R asli jika semakin kecil akan semakin bagus\r\n",
    "norm_lrfm['Recency'] = 1-norm_lrfm['Recency']\r\n",
    "\r\n",
    "norm_lrfm.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# K-Means Clustering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn import preprocessing\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.manifold import TSNE\r\n",
    "\r\n",
    "from sklearn.cluster import KMeans\r\n",
    "\r\n",
    "from sklearn.metrics import silhouette_score\r\n",
    "from sklearn.metrics import calinski_harabasz_score\r\n",
    "from sklearn.metrics import davies_bouldin_score\r\n",
    "\r\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\r\n",
    "from kneed import KneeLocator"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find K Optimum"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Elbow method Viz\r\n",
    "K_elbow = range(1,10)\r\n",
    "inertias = []\r\n",
    "distortions = []\r\n",
    "\r\n",
    "for k in K_elbow: \r\n",
    "    #Building and fitting the model \r\n",
    "    kmeanModel = KMeans(n_clusters=k, n_init=10, max_iter=100, random_state=123)\r\n",
    "    kmeanModel.fit(norm_lrfm)     \r\n",
    "\r\n",
    "    #Elbow Method metrics\r\n",
    "    inertias.append(kmeanModel.inertia_) \r\n",
    "    distortions.append(sum(np.min(cdist(lrfm, kmeanModel.cluster_centers_, \r\n",
    "                      'euclidean'),axis=1)) / norm_lrfm.shape[0])     \r\n",
    "\r\n",
    "kn = KneeLocator(K_elbow, inertias, curve='convex', direction='decreasing')\r\n",
    "print(\"Elbow at K =\", kn.knee)\r\n",
    "\r\n",
    "plt.plot(K_elbow, inertias, 'bx-') \r\n",
    "plt.xlabel('Values of K') \r\n",
    "plt.ylabel('SSE') \r\n",
    "plt.title('The Elbow Method using SSE') \r\n",
    "plt.vlines(kn.knee, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\r\n",
    "plt.savefig('Grafik/Elbow Method using Inertia.png', format='png', dpi=1000)\r\n",
    "plt.show() \r\n",
    "\r\n",
    "kn = KneeLocator(K_elbow, distortions, curve='convex', direction='decreasing')\r\n",
    "print(\"Elbow at K =\", kn.knee)\r\n",
    "\r\n",
    "plt.plot(K_elbow, distortions, 'bx-') \r\n",
    "plt.xlabel('Values of K') \r\n",
    "plt.ylabel('Distortion') \r\n",
    "plt.title('The Elbow Method using SSE') \r\n",
    "plt.vlines(kn.knee, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\r\n",
    "plt.savefig('Grafik/Elbow Method using distortion.png', format='png', dpi=1000)\r\n",
    "plt.show() "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "K = range(2,10)\r\n",
    "# fig, ax = plt.subplots(4, 2, figsize=(15,15))\r\n",
    "\r\n",
    "# Silhouette Method metrics\r\n",
    "euclidean = []\r\n",
    "ch_index = []\r\n",
    "db_index = []\r\n",
    "  \r\n",
    "for k in K: \r\n",
    "    #Building and fitting the model \r\n",
    "    kmeanModel = KMeans(n_clusters=k, n_init=10, max_iter=100, random_state=123)\r\n",
    "    kmeanModel.fit(norm_lrfm)     \r\n",
    "    \r\n",
    "    # Silhouette Method metrics\r\n",
    "    euclidean.append(silhouette_score(norm_lrfm, kmeanModel.labels_, metric='euclidean'))\r\n",
    "\r\n",
    "    # Silhouette also\r\n",
    "    # q, mod = divmod(k, 2)\r\n",
    "    # visualizer = SilhouetteVisualizer(kmeanModel, colors='yellowbrick', ax=ax[q-1][mod])\r\n",
    "    # visualizer.fit(norm_lrfm)\r\n",
    "\r\n",
    "    # C-H Index\r\n",
    "    ch_index.append(calinski_harabasz_score(norm_lrfm,kmeanModel.labels_))\r\n",
    "\r\n",
    "    # DB Index\r\n",
    "    db_index.append(davies_bouldin_score(norm_lrfm,kmeanModel.labels_))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ymax = max(euclidean)\r\n",
    "xpos = euclidean.index(ymax)\r\n",
    "xmax = K[xpos]\r\n",
    "\r\n",
    "print(\"Highest Euclidean Value = %s at K=%s\" % (ymax, xmax,))\r\n",
    "plt.plot(K, euclidean, 'bo-') \r\n",
    "plt.xlabel('Values of K') \r\n",
    "plt.ylabel('Shilhouette Index') \r\n",
    "plt.title('The Silhouette Method using Euclidean Distance') \r\n",
    "plt.vlines(xmax, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\r\n",
    "plt.savefig('Grafik/Silhouette Method using Euclidean Distance.png', format='png', dpi=1000)\r\n",
    "plt.show() "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "euclidean"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# CH Index Viz\r\n",
    "ymax = max(ch_index)\r\n",
    "xpos = ch_index.index(ymax)\r\n",
    "xmax = K[xpos]\r\n",
    "\r\n",
    "print(\"Highest CH-Index Value = %s at K=%s\" % (ymax, xmax,))\r\n",
    "plt.plot(K, ch_index, 'bo-') \r\n",
    "plt.xlabel('Values of K') \r\n",
    "plt.ylabel('CH Index') \r\n",
    "plt.title('CH Index for k=2 to k=9') \r\n",
    "plt.vlines(xmax, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\r\n",
    "plt.savefig('Grafik/CH Index.png', format='png', dpi=1000)\r\n",
    "plt.show() "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# DB Index Viz\r\n",
    "ymin = min(db_index)\r\n",
    "xpos = db_index.index(ymin)\r\n",
    "xmax = K[xpos]\r\n",
    "\r\n",
    "print(\"Lowest DB Index Value = %s at K=%s\" % (ymax, xmax,))\r\n",
    "plt.plot(K, db_index, 'bo-') \r\n",
    "plt.xlabel('Values of K') \r\n",
    "plt.ylabel('DB Index') \r\n",
    "plt.title('Davis Bouldin Index for k=2 to k=9') \r\n",
    "plt.vlines(xmax, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\r\n",
    "plt.show() "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clustering!!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Set K Value\r\n",
    "K_fix = 3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def kmeans(normalised_df_lrfm, clusters_number, original_df_lrfm):\r\n",
    "    \r\n",
    "    kmeans = KMeans(n_clusters = clusters_number, random_state = 123)\r\n",
    "    kmeans.fit(normalised_df_lrfm)\r\n",
    "\r\n",
    "    # Extract cluster labels\r\n",
    "    cluster_labels = kmeans.labels_\r\n",
    "        \r\n",
    "    # Create a cluster label column in original dataset\r\n",
    "    df_new = original_df_lrfm.assign(Cluster = cluster_labels)\r\n",
    "    df_new['Cluster'] += 1\r\n",
    "    return df_new\r\n",
    "\r\n",
    "def flatened2d(df_new):\r\n",
    "    # Initialise TSNE\r\n",
    "    model = TSNE(random_state=1)\r\n",
    "    transformed = model.fit_transform(df_new)\r\n",
    "    \r\n",
    "    # Plot t-SNE\r\n",
    "    sns.scatterplot(x=transformed[:,0], y=transformed[:,1], hue=df_new['Cluster'], style=df_new['Cluster'], palette=\"Set1\")\r\n",
    "\r\n",
    "def snake_plot(normalised_df_lrfm, df_lrfm_kmeans, df_lrfm_original):\r\n",
    "\r\n",
    "    normalised_df_lrfm = pd.DataFrame(normalised_df_lrfm, \r\n",
    "                                       index=df_lrfm_original.index, \r\n",
    "                                       columns=df_lrfm_original.columns)\r\n",
    "    normalised_df_lrfm['Cluster'] = df_lrfm_kmeans['Cluster']\r\n",
    "\r\n",
    "    # Melt data into long format\r\n",
    "    df_melt = pd.melt(normalised_df_lrfm.reset_index(), \r\n",
    "                        id_vars=['telp', 'Cluster'],\r\n",
    "                        value_vars=['Length', 'Recency', 'Frequency', 'Monetary'], \r\n",
    "                        var_name='Metric', \r\n",
    "                        value_name='Value')\r\n",
    "\r\n",
    "    plt.xlabel('Metric')\r\n",
    "    plt.ylabel('Value')\r\n",
    "    sns.pointplot(data=df_melt, x='Metric', y='Value', hue='Cluster')\r\n",
    "    \r\n",
    "    return\r\n",
    "\r\n",
    "def threeD_plot(df_merge):\r\n",
    "    from mpl_toolkits.mplot3d import Axes3D\r\n",
    "    fig = plt.figure(figsize=(16, 9))\r\n",
    "    ax = fig.gca(projection='3d')\r\n",
    "    ax.set_title(\"3D Plot of K = %s\" % (K_fix))\r\n",
    "    \r\n",
    "    x = np.array(df_merge['Recency_norm'])\r\n",
    "    y = np.array(df_merge['Frequency_norm'])\r\n",
    "    z = np.array(df_merge['Monetary_norm'])\r\n",
    "    ax.scatter(x,y,z, s=(df_merge['Length_norm']*40), marker=\"s\", c=df_merge[\"Cluster\"], cmap=\"rainbow\")\r\n",
    "    ax.set_xlabel('Recency')\r\n",
    "    ax.set_ylabel('Frequency')\r\n",
    "    ax.set_zlabel('Monetary')\r\n",
    "\r\n",
    "    return\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#CLlustering K-Means\r\n",
    "df_cluster_fix = kmeans(norm_lrfm, K_fix, lrfm)\r\n",
    "\r\n",
    "df_lrfm_all = pd.merge(df_cluster_fix, norm_lrfm, on='telp', suffixes=('_real', '_norm'))\r\n",
    "df_lrfm_all.to_csv(\"Hasil/Data_TA Clustered_LRFM.csv\")\r\n",
    "df_lrfm_all"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_lrfm_all.iloc[:,[5,6,7,8]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Flattened Scatter Plot\r\n",
    "plt.figure(figsize=(16, 8))\r\n",
    "plt.title('Flattened 2 Dimension Graph of %s Clusters' % (K_fix))\r\n",
    "flatened2d(df_cluster_fix)\r\n",
    "plt.savefig('Grafik/Flattened 2 Dimension Graph.png', format='png', dpi=300)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#3D Plot\r\n",
    "threeD_plot(df_lrfm_all)\r\n",
    "plt.savefig('Grafik/Cluster_is_3-3dplot.png', format='png', dpi=300)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#matrix scatterplot\r\n",
    "sns.set_theme(style=\"ticks\")\r\n",
    "scat = df_lrfm_all.iloc[:,-5:]\r\n",
    "sns.pairplot(scat, hue='Cluster', palette= {1: \"blue\", 2: \"green\", 3: \"red\"}, markers={1: \"o\", 2: \"s\", 3: \"^\"}, diag_kind=\"hist\", corner=True)\r\n",
    "plt.savefig('Grafik/Cluster_is_3-scatterdplot.png', format='png', dpi=300)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Snake Plot\r\n",
    "plt.figure(figsize=(16, 8))\r\n",
    "plt.title(\"Snake Plot of K = %s\" % (K_fix))\r\n",
    "snake_plot(norm_lrfm, df_cluster_fix, lrfm)\r\n",
    "plt.savefig('Grafik/Cluster_is_3-snakeplot.png', format='png', dpi=300)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#BoxPlot for Real Data\r\n",
    "fig = plt.figure(figsize=(10, 5))\r\n",
    "ax = sns.boxplot(x=\"Cluster\", y=\"Length_real\", data=df_lrfm_all, width=0.3, whis=10)\r\n",
    "L_mean = df_lrfm_all[\"Length_real\"].mean()\r\n",
    "plt.plot([-0.5, 2.5], [L_mean, L_mean], 'k-', lw=2, dashes=[5, 2], color='purple', label=\"population mean\")\r\n",
    "plt.title('Boxplot for Length each cluster') \r\n",
    "plt.legend()\r\n",
    "plt.savefig('Grafik/boxplot L.png', format='png', dpi=300)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "fig = plt.figure(figsize=(10, 5))\r\n",
    "ax = sns.boxplot(x=\"Cluster\", y=\"Recency_real\", data=df_lrfm_all, width=0.3, whis=10)\r\n",
    "R_mean = df_lrfm_all[\"Recency_real\"].mean()\r\n",
    "plt.plot([-0.5, 2.5], [R_mean, R_mean], 'k-', lw=2, dashes=[5, 2], color='purple', label=\"population mean\")\r\n",
    "plt.title('Boxplot for Recency each cluster') \r\n",
    "plt.legend()\r\n",
    "plt.savefig('Grafik/boxplot R.png', format='png', dpi=300)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "fig = plt.figure(figsize=(10, 5))\r\n",
    "plt.yscale(\"log\")\r\n",
    "ax = sns.boxplot(x=\"Cluster\", y=\"Frequency_real\", data=df_lrfm_all, width=0.3, whis=100)\r\n",
    "F_mean = df_lrfm_all[\"Frequency_real\"].mean()\r\n",
    "plt.plot([-0.5, 2.5], [F_mean, F_mean], 'k-', lw=2, dashes=[5, 2], color='purple', label=\"population mean\")\r\n",
    "plt.title('Boxplot for Frequency each cluster') \r\n",
    "plt.legend()\r\n",
    "plt.savefig('Grafik/boxplot F.png', format='png', dpi=300)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "fig = plt.figure(figsize=(10, 5))\r\n",
    "plt.yscale(\"log\")\r\n",
    "ax = sns.boxplot(x=\"Cluster\", y=\"Monetary_real\", data=df_lrfm_all, width=0.3, whis=100)\r\n",
    "M_mean = df_lrfm_all[\"Monetary_real\"].mean()\r\n",
    "plt.plot([-0.5, 2.5], [M_mean, M_mean], 'k-', lw=2, dashes=[5, 2], color='purple', label=\"population mean\")\r\n",
    "plt.title('Boxplot for Monetary each cluster')\r\n",
    "plt.legend()\r\n",
    "plt.savefig('Grafik/boxplot M.png', format='png', dpi=300)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Boxplot for Normalized data\r\n",
    "fig = plt.figure(figsize=(10, 5))\r\n",
    "ax = sns.boxplot(x=\"Cluster\", y=\"Length_norm\", data=df_lrfm_all, width=0.3, whis=10)\r\n",
    "plt.title('Boxplot for Normalized Length each cluster') \r\n",
    "L_norm_mean = df_lrfm_all[\"Length_norm\"].mean()\r\n",
    "plt.plot([-0.5, 2.5], [L_norm_mean, L_norm_mean], 'k-', lw=2, dashes=[5, 2], color='purple', label=\"population mean\")\r\n",
    "plt.legend()\r\n",
    "plt.savefig('Grafik/Cluster_is_3-L_boxplot_norm.png', format='png', dpi=300)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "fig = plt.figure(figsize=(10, 5))\r\n",
    "ax = sns.boxplot(x=\"Cluster\", y=\"Recency_norm\", data=df_lrfm_all, width=0.3, whis=10)\r\n",
    "plt.title('Boxplot for Normalized Recency each cluster') \r\n",
    "R_norm_mean = df_lrfm_all[\"Recency_norm\"].mean()\r\n",
    "plt.plot([-0.5, 2.5], [R_norm_mean, R_norm_mean], 'k-', lw=2, dashes=[5, 2], color='purple', label=\"population mean\")\r\n",
    "plt.legend()\r\n",
    "plt.savefig('Grafik/Cluster_is_3-R_boxplot_norm.png', format='png', dpi=300)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "fig = plt.figure(figsize=(10, 5))\r\n",
    "ax = sns.boxplot(x=\"Cluster\", y=\"Frequency_norm\", data=df_lrfm_all, width=0.3, whis=10)\r\n",
    "plt.title('Boxplot for Normalized Frequency each cluster') \r\n",
    "F_norm_mean = df_lrfm_all[\"Frequency_norm\"].mean()\r\n",
    "plt.plot([-0.5, 2.5], [F_norm_mean, F_norm_mean], 'k-', lw=2, dashes=[5, 2], color='purple', label=\"population mean\")\r\n",
    "plt.legend()\r\n",
    "plt.savefig('Grafik/Cluster_is_3-F_boxplot_norm.png', format='png', dpi=300)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "fig = plt.figure(figsize=(10, 5))\r\n",
    "ax = sns.boxplot(x=\"Cluster\", y=\"Monetary_norm\", data=df_lrfm_all, width=0.3, whis=10)\r\n",
    "plt.title('Boxplot for Normalized Monetary each cluster') \r\n",
    "M_norm_mean = df_lrfm_all[\"Monetary_norm\"].mean()\r\n",
    "plt.plot([-0.5, 2.5], [M_norm_mean, M_norm_mean], 'k-', lw=2, dashes=[5, 2], color='purple', label=\"population mean\")\r\n",
    "plt.legend()\r\n",
    "plt.savefig('Grafik/Cluster_is_3-M_boxplot_norm.png', format='png', dpi=300)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Violin Plot\r\n",
    "plt.figure(figsize=(8,4))\r\n",
    "sns.violinplot(x='Cluster', y='Length_real', data=df_lrfm_all, scale='width', inner='quartile')\r\n",
    "plt.title('Violin Plot of Length each cluster', fontsize=14)\r\n",
    "plt.savefig('Grafik/violin 1_L_real.png', format='png', dpi=300)\r\n",
    "# plt.show()\r\n",
    "\r\n",
    "plt.figure(figsize=(8,4))\r\n",
    "sns.violinplot(x='Cluster', y='Recency_real', data=df_lrfm_all, scale='width', inner='quartile')\r\n",
    "plt.title('Violin Plot of Recency each cluster', fontsize=14)\r\n",
    "plt.savefig('Grafik/violin 2_F_real.png', format='png', dpi=300)\r\n",
    "# plt.show()\r\n",
    "\r\n",
    "plt.figure(figsize=(8,4))\r\n",
    "sns.violinplot(x='Cluster', y='Frequency_real', data=df_lrfm_all, scale='width', inner='quartile')\r\n",
    "plt.yscale(\"log\")\r\n",
    "plt.title('Violin Plot of Frequency each cluster (log scale)', fontsize=14)\r\n",
    "plt.savefig('Grafik/violin 3_F_real.png', format='png', dpi=300)\r\n",
    "# plt.show()\r\n",
    "\r\n",
    "plt.figure(figsize=(8,4))\r\n",
    "sns.violinplot(x='Cluster', y='Monetary_real', data=df_lrfm_all, scale='width', inner='quartile')\r\n",
    "plt.yscale(\"log\")\r\n",
    "plt.title('Violin Plot of Monetary each cluster (log scale)', fontsize=14)\r\n",
    "plt.savefig('Grafik/violin 4_M_real.png', format='png', dpi=300)\r\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Violin Plot\r\n",
    "plt.figure(figsize=(8,4))\r\n",
    "sns.violinplot(x='Cluster', y='Length_norm', data=df_lrfm_all, scale='width', inner='quartile')\r\n",
    "plt.title('Violin Plot of Normalized Length each cluster', fontsize=14)\r\n",
    "plt.savefig('Grafik/violin 1_L_norm.png', format='png', dpi=300)\r\n",
    "# plt.show()\r\n",
    "\r\n",
    "plt.figure(figsize=(8,4))\r\n",
    "sns.violinplot(x='Cluster', y='Recency_norm', data=df_lrfm_all, scale='width', inner='quartile')\r\n",
    "plt.title('Violin Plot of Normalized Recency each cluster', fontsize=14)\r\n",
    "plt.savefig('Grafik/violin 2_R_norm.png', format='png', dpi=300)\r\n",
    "# plt.show()\r\n",
    "\r\n",
    "plt.figure(figsize=(8,4))\r\n",
    "sns.violinplot(x='Cluster', y='Frequency_norm', data=df_lrfm_all, scale='width', inner='quartile')\r\n",
    "plt.title('Violin Plot of Normalized Frequency each cluster', fontsize=14)\r\n",
    "plt.savefig('Grafik/violin 3_F_norm.png', format='png', dpi=300)\r\n",
    "# plt.show()\r\n",
    "\r\n",
    "plt.figure(figsize=(8,4))\r\n",
    "sns.violinplot(x='Cluster', y='Monetary_norm', data=df_lrfm_all, scale='width', inner='quartile')\r\n",
    "plt.title('Violin Plot of Normalized Monetary each cluster', fontsize=14)\r\n",
    "plt.savefig('Grafik/violin 4_M_norm.png', format='png', dpi=300)\r\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_lrfm_all"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(1, K_fix+1) :\r\n",
    "    #slice data\r\n",
    "    df = df_lrfm_all[lambda x: x['Cluster'] == i]\r\n",
    "    \r\n",
    "    fig = plt.figure(figsize=(5, 5))\r\n",
    "    plt.ylim(0, 370)\r\n",
    "    ax = sns.boxplot(data=df.iloc[:,:2], width=0.3, whis=10)\r\n",
    "    plt.title(\"Boxplot for Cluster %s\" % (i))\r\n",
    "    plt.savefig(\"Grafik/boxplot LR Cluster %s.png\" % (i), format='png', dpi=300)\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(1, K_fix+1) :\r\n",
    "    df = df_lrfm_all[lambda x: x['Cluster'] == i]\r\n",
    "    \r\n",
    "    fig = plt.figure(figsize=(3, 5))\r\n",
    "    plt.ylim(0, 100)\r\n",
    "    ax = sns.boxplot(data=df.iloc[:,2], width=0.3, whis=10)\r\n",
    "    ax.set(xlabel=\"Frequency\", xticklabels=[])\r\n",
    "    plt.title(\"Boxplot for Cluster %s\" % (i))\r\n",
    "    plt.savefig(\"Grafik/boxplot F Cluster %s.png\" % (i), format='png', dpi=300)\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(1, K_fix+1) :\r\n",
    "    df = df_lrfm_all[lambda x: x['Cluster'] == i]\r\n",
    "    \r\n",
    "    fig = plt.figure(figsize=(3, 5))\r\n",
    "    plt.ylim(1e3, 4.5e7)\r\n",
    "    ax = sns.boxplot(data=df.iloc[:,3], width=0.3, whis=10)\r\n",
    "    ax.set(yscale=\"log\", xlabel=\"Monetary\", xticklabels=[])\r\n",
    "    plt.title(\"Boxplot for Cluster %s\" % (i))\r\n",
    "    plt.savefig(\"Grafik/boxplot M Cluster %s.png\" % (i), format='png', dpi=300)\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cluster Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cluster_char = df_cluster_fix.reset_index().groupby(['Cluster']).describe()\r\n",
    "cluster_char.transpose().to_csv(\"Hasil/Data_TA Cluster_characteristics.csv\")\r\n",
    "cluster_char"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_cluster_fix.groupby(['Cluster']).agg(['mean', 'median', 'sum']).round(3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mean from all dataframe\r\n",
    "df_lrfm_all.mean(axis=0).round(3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Menghitung CLV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Nilai bobot didapatkan dari file excel\r\n",
    "AHP = {\r\n",
    "    'Length' : 0.052,\r\n",
    "    'Recency' : 0.099,\r\n",
    "    'Frequency' : 0.362,\r\n",
    "    'Monetary' : 0.486}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_lrfm_all['CLV'] = (df_lrfm_all['Length_norm']*AHP['Length'] + df_lrfm_all['Recency_norm']*AHP['Recency'] + df_lrfm_all['Frequency_norm']*AHP['Frequency'] + df_lrfm_all['Monetary_norm']*AHP['Monetary'])\n",
    "display(df_lrfm_all['CLV'].describe())\n",
    "\n",
    "#Agar angka lebih cantik dan mudah dibaca, kita kalikan 1000\n",
    "df_lrfm_all['CLV'] = df_lrfm_all['CLV']*100\n",
    "plt.title('Distribution of CLV')\n",
    "sns.distplot(df_lrfm_all['CLV'], kde=False)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_lrfm_all.head(7)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rank CLV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_lrfm_all.groupby(['Cluster']).agg('mean').sort_values(by=['CLV'], ascending=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def clv_values(df):\n",
    "    clv_cluster = df.groupby(['Cluster']).agg({\n",
    "        'Length_real': ['min', 'max', 'mean'],\n",
    "        'Recency_real': ['min', 'max', 'mean'],\n",
    "        'Frequency_real': ['min', 'max', 'mean'],\n",
    "        'Monetary_real': ['min', 'max', 'mean'],\n",
    "        'CLV' : ['min', 'max', 'mean', 'median']\n",
    "    }).round(0)\n",
    "    \n",
    "    return clv_cluster"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clv_values(df_lrfm_all).sort_values(by=[('CLV','mean')], ascending=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Market Basket Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.frequent_patterns import association_rules"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Join Dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_basket_all = pd.merge(df_clean, df_cluster_fix, on='telp', how='left')\r\n",
    "df_basket_all = df_basket_all[['delivery_date', 'no_order', 'name', 'telp', 'produk', 'qty', 'Cluster']].copy()\r\n",
    "df_basket_all.to_csv(\"Hasil/Data_TA Clustered_Transaksi.csv\")\r\n",
    "\r\n",
    "#drop NA from frequency outlier\r\n",
    "df_basket_all.dropna(subset=['Cluster'], inplace=True)\r\n",
    "\r\n",
    "print(\"Dataset dimension : \" + str(df_basket_all.shape))\r\n",
    "print('Jumlah Customer : ' + str(len(pd.unique(df_basket_all['telp']))))\r\n",
    "print('Jumlah Transaksi : ' + str(len(pd.unique(df_basket_all['no_order']))))\r\n",
    "\r\n",
    "#clean the product names\r\n",
    "df_basket_all['produk'] = df_basket_all['produk'].str.strip()\r\n",
    "df_basket_all['no_order'] = df_basket_all['no_order'].astype('str')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#one hot encode the basket\r\n",
    "def encode_units(x):\r\n",
    "    if x <= 0:\r\n",
    "        return 0\r\n",
    "    if x >= 1:\r\n",
    "        return 1\r\n",
    "\r\n",
    "#create FP-Growth MBA for every cluster\r\n",
    "def createMBA(basket_data, min_sup) :\r\n",
    "    totalTransactions = len(basket_data.index)\r\n",
    "    totalCustomers = len(pd.unique(basket_data['telp']))\r\n",
    "    # minTransaction = totalTransactions*0.005\r\n",
    "    # min_support_calc = minTransaction/totalTransactions\r\n",
    "\r\n",
    "    print('Jumlah Pelanggan = ', totalCustomers)\r\n",
    "    print('Jumlah Transaksi yang dianalisis = ', totalTransactions)\r\n",
    "    print('Nilai Support Minimum = ', round(min_sup*100, 4), '%')\r\n",
    "\r\n",
    "    basket = basket_data.groupby(['no_order', 'produk'])['qty'].sum().unstack().reset_index().fillna(0).set_index('no_order')\r\n",
    "    basket_sets = basket.applymap(encode_units)\r\n",
    "    basket_sets.dropna(inplace=True)\r\n",
    "    basket_sets = basket_sets.astype(int)\r\n",
    "    # display(basket_sets.head(5))\r\n",
    "\r\n",
    "    #create frequent items sets with clculated minimum support\r\n",
    "    frequent_itemsets = fpgrowth(basket_sets, min_support=min_sup, use_colnames=True)\r\n",
    "    # display(frequent_itemsets.describe())\r\n",
    "\r\n",
    "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0)\r\n",
    "    rules.sort_values('support', ascending = False, inplace = True)\r\n",
    "\r\n",
    "    createMBA.rules = rules\r\n",
    "    \r\n",
    "    return rules\r\n",
    "\r\n",
    "#Apriori\r\n",
    "from mlxtend.frequent_patterns import apriori\r\n",
    "\r\n",
    "def aprioriMBA(basket_data, min_sup) :\r\n",
    "    totalTransactions = len(basket_data.index)\r\n",
    "    totalCustomers = len(pd.unique(basket_data['telp']))\r\n",
    "    # minTransaction = totalTransactions*0.005\r\n",
    "    # min_support_calc = minTransaction/totalTransactions\r\n",
    "\r\n",
    "    print('Jumlah Pelanggan = ', totalCustomers)\r\n",
    "    print('Jumlah Transaksi yang dianalisis = ', totalTransactions)\r\n",
    "    print('Nilai Support Minimum = ', round(min_sup*100, 4), '%')\r\n",
    "\r\n",
    "    basket = basket_data.groupby(['no_order', 'produk'])['qty'].sum().unstack().reset_index().fillna(0).set_index('no_order')\r\n",
    "    basket_sets = basket.applymap(encode_units)\r\n",
    "    basket_sets.dropna(inplace=True)\r\n",
    "    basket_sets = basket_sets.astype(int)\r\n",
    "    # display(basket_sets.head(5))\r\n",
    "\r\n",
    "    #create frequent items sets with clculated minimum support\r\n",
    "    frequent_itemsets = apriori(basket_sets, min_support=min_sup, use_colnames=True)\r\n",
    "    # display(frequent_itemsets.describe())\r\n",
    "\r\n",
    "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0)\r\n",
    "    rules.sort_values('support', ascending = False, inplace = True)\r\n",
    "\r\n",
    "    aprioriMBA.rules = rules\r\n",
    "    \r\n",
    "    return rules"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#MBA w/ Clustering minsup 1%\r\n",
    "for i in range(1, K_fix+1) :\r\n",
    "    #slice data\r\n",
    "    print(\"Market Basket Analysis for Cluster\", i)\r\n",
    "    basket_data = df_basket_all[lambda x: x['Cluster'] == i]\r\n",
    "\r\n",
    "    createMBA(basket_data, 0.01)\r\n",
    "    mean_suppport = createMBA.rules['support'].mean()\r\n",
    "    print('rules berhasil dibangkitkan = ', len(createMBA.rules.index))\r\n",
    "    print('rerata support = ', mean_suppport)\r\n",
    "    \r\n",
    "    \r\n",
    "    display(createMBA.rules.head(5))\r\n",
    "    createMBA.rules.to_csv(\"Hasil/Data_TA FPGrowth(minsup0.01)_Cluster_%s.csv\" % (i,), ';')\r\n",
    "    # rules[(rules['lift'] >= 0.2) & (rules['confidence'] >= 0.1)].sort_values(by=['confidence', 'lift'], ascending=False).to_csv(\"Data/Ternakmart_Results_FPGrowth_Cluster_%s.csv\" % (i,), 'a', newline='')\r\n",
    "    print(\"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Apriori MBA w/ Clustering minsup 1%\r\n",
    "for i in range(1, K_fix+1) :\r\n",
    "    #slice data\r\n",
    "    print(\"Market Basket Analysis for Cluster\", i)\r\n",
    "    basket_data = df_basket_all[lambda x: x['Cluster'] == i]\r\n",
    "\r\n",
    "    aprioriMBA(basket_data, 0.01)\r\n",
    "    mean_suppport = aprioriMBA.rules['support'].mean()\r\n",
    "    print('rules berhasil dibangkitkan = ', len(aprioriMBA.rules.index))\r\n",
    "    print('rerata support = ', mean_suppport)\r\n",
    "    \r\n",
    "    display(aprioriMBA.rules.head(5))\r\n",
    "    aprioriMBA.rules.to_csv(\"Hasil/Data_TA Apriori(minsup0.01)_Cluster_%s.csv\" % (i,), ';')\r\n",
    "    # rules[(rules['lift'] >= 0.2) & (rules['confidence'] >= 0.1)].sort_values(by=['confidence', 'lift'], ascending=False).to_csv(\"Data/Ternakmart_Results_FPGrowth_Cluster_%s.csv\" % (i,), 'a', newline='')\r\n",
    "    print(\"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#MBA w/ Clustering minsup 0.5%\r\n",
    "for i in range(1, K_fix+1) :\r\n",
    "    #slice data\r\n",
    "    print(\"Market Basket Analysis for Cluster\", i)\r\n",
    "    basket_data = df_basket_all[lambda x: x['Cluster'] == i]\r\n",
    "\r\n",
    "    createMBA(basket_data, 0.005)\r\n",
    "    print('rules berhasil dibangkitkan = ', len(createMBA.rules.index))\r\n",
    "\r\n",
    "    display(createMBA.rules.head(10))\r\n",
    "\r\n",
    "    plt.scatter(createMBA.rules['support'], createMBA.rules['confidence'], alpha=0.5)\r\n",
    "    # plt.xlabel('support')\r\n",
    "    # plt.ylabel('confidence')\r\n",
    "    # plt.title('Support vs Confidence')\r\n",
    "    # plt.show()\r\n",
    "\r\n",
    "    createMBA.rules.to_csv(\"Hasil/Data_TA FPGrowth (minsup0.005)_Cluster_%s.csv\" % (i,), ';')\r\n",
    "    # rules[(rules['lift'] >= 0.2) & (rules['confidence'] >= 0.1)].sort_values(by=['confidence', 'lift'], ascending=False).to_csv(\"Data/Ternakmart_Results_FPGrowth_Cluster_%s.csv\" % (i,), 'a', newline='')\r\n",
    "    print(\"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#MBA w/o Clustering\n",
    "createMBA(df_basket_all, 0.01)\n",
    "print('rules berhasil dibangkitkan = ', len(createMBA.rules.index))\n",
    "\n",
    "display(createMBA.rules.head(10))\n",
    "createMBA.rules.to_csv(\"Hasil/Data_EXP FPGrowth_NO_Cluster_%s.csv\", ';')\n",
    "# rules[(rules['lift'] >= 0.2) & (rules['confidence'] >= 0.1)].sort_values(by=['confidence', 'lift'], ascending=False).to_csv(\"Data/Ternakmart_Results_FPGrowth_Cluster_All.csv\", 'a', newline='')\n",
    "print(\"\\n \\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#MBA w/o Jabmilk\n",
    "jabmilk = ['JABMILK', 'JAB MILK']\n",
    "df_basket_nonjabmilk = df_basket_all[~df_basket_all['produk'].str.contains('|'.join(jabmilk))]\n",
    "\n",
    "for i in range(1, K_fix+1) :\n",
    "    #slice data\n",
    "    print(\"Market Basket Analysis (Without Jabmilk) for Cluster\", i)\n",
    "    basket_data = df_basket_nonjabmilk[lambda x: x['Cluster'] == i]\n",
    "\n",
    "    createMBA(basket_data, 0.01)\n",
    "    print('rules berhasil dibangkitkan = ', len(createMBA.rules.index))\n",
    "\n",
    "    display(createMBA.rules.head(10))\n",
    "    createMBA.rules.to_csv(\"Hasil/Data_EXP FPGrowth_nonjabmilk_Cluster_%s.csv\" % (i,), ';')\n",
    "    # rules[(rules['lift'] >= 0.2) & (rules['confidence'] >= 0.1)].sort_values(by=['confidence', 'lift'], ascending=False).to_csv(\"Data/Ternakmart_Results_nonjabmilk_FPGrowth_Cluster_%s.csv\" % (i,), 'a', newline='')\n",
    "    print(\"\\n \\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#MBA w/o Clustering w/o Jabmilk\n",
    "createMBA(df_basket_nonjabmilk, 0.007)\n",
    "print('rules berhasil dibangkitkan = ', len(createMBA.rules.index))\n",
    "createMBA.rules.to_csv(\"Hasil/Data_EXP FPGrowth_nonjabmilk_NO_Cluster_%s.csv\", ';')\n",
    "\n",
    "display(createMBA.rules.head(10))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}